{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yXPmKxSxFTWD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "dataset_path = 'FaceDisguiseDatabase/FaceAll'\n",
        "data = []\n",
        "labels = []\n",
        "image_count = 0\n",
        "person_count = 0\n",
        "current_label = None"
      ],
      "metadata": {
        "id": "nmusil1mFc5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image_file in os.listdir(dataset_path):\n",
        "    if image_count >= 6:\n",
        "        image_count = 0\n",
        "        person_count += 1\n",
        "        continue\n",
        "\n",
        "    image_path = os.path.join(dataset_path, image_file)\n",
        "\n",
        "    if os.path.isdir(image_path):\n",
        "        continue\n",
        "\n",
        "    if os.path.isfile(image_path):\n",
        "        try:\n",
        "            image = cv2.imread(image_path)\n",
        "            image = cv2.resize(image, (64, 64))\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            data.append(image)\n",
        "            if image_count == 0:\n",
        "                current_label = f\"Person_{person_count}\"\n",
        "            labels.append(current_label)\n",
        "\n",
        "            image_count += 1\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {image_path}: {e}\")"
      ],
      "metadata": {
        "id": "5rOtGTiZFk4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array(data, dtype=\"uint8\")\n",
        "labels = np.array(labels)\n",
        "data = data / 255.0\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "one_hot_labels = to_categorical(encoded_labels)"
      ],
      "metadata": {
        "id": "2qGyRY-_FwKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(len(np.unique(encoded_labels)), activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "7OUH3t2FFxr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "checkpoint_path = \"best_model.h5\"\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "history = model.fit(data, one_hot_labels, epochs=epochs, validation_split=0.1, callbacks=[checkpoint])"
      ],
      "metadata": {
        "id": "47W3IOKVFz8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"final_model.h5\")\n",
        "if os.path.exists(checkpoint_path):\n",
        "    best_model = models.load_model(checkpoint_path)\n",
        "    best_loss, best_acc = best_model.evaluate(data, one_hot_labels, verbose=2)\n",
        "    print(f'Best model accuracy: {best_acc}')\n",
        "    predictions = best_model.predict(data)\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "    true_classes = np.argmax(one_hot_labels, axis=1)\n",
        "    unique_labels = np.unique(np.concatenate((predicted_classes, true_classes)))\n",
        "    target_names = label_encoder.inverse_transform(unique_labels)\n",
        "\n",
        "    report = classification_report(true_classes, predicted_classes, labels=unique_labels, target_names=target_names)\n",
        "    print(report)\n",
        "else:\n",
        "    print(\"Best model checkpoint not found.\")"
      ],
      "metadata": {
        "id": "eagJKq7VF1TK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(\"Total time taken:\", total_time)"
      ],
      "metadata": {
        "id": "8ZQyJQNZF2gk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}